ğŸŒ«ï¸ Delhi AQI Index Prediction

Spatio-Temporal Air Quality Forecasting using Machine Learning

ğŸ“Œ Project Overview

Air quality monitoring data suffers from severe missingness, spatial sparsity, and strong temporal dependencies.
This project builds an end-to-end machine learning pipeline to predict major air pollutants in Delhi by combining:

Hybrid data imputation (temporal + spatial)

Time-aware feature engineering

Robust model validation

City-wide spatial visualization (heatmaps)

Two tree-based models â€” XGBoost and LightGBM â€” are trained and compared across six pollutants.

ğŸ§  Key Contributions

Hybrid Imputation Strategy

Short gaps: Linear interpolation

Medium gaps: Kalman smoothing

Long gaps: Spatial IDW using tuned power parameters

Spatio-Temporal Modeling

Per-station time series combined with geographic coordinates

Lag and rolling-window features

Leakage-Safe Evaluation

Time-based trainâ€“test split (Expanding-Window/Single-Shot Forecast)

No future information used in training

Per-Pollutant Modeling

Separate models for PM2.5, PM10, NOx, SOâ‚‚, CO, and Oâ‚ƒ

City-Scale Visualization

7-day hourly heatmaps using spatial interpolation

ğŸ—‚ï¸ Dataset Description

Stations: 40 monitoring stations across Delhi

Time span: 2009 â€“ 2023 (hourly data)

Pollutants:

PM2.5

PM10

NOx

SOâ‚‚

CO

Oâ‚ƒ

Raw data structure:

DL.data â†’ station-wise time series

DL.details â†’ station coordinates

locs.pred â†’ spatial prediction grid

âš™ï¸ Project Pipeline

Raw AQI Data
        â†“        â†“
IDW p-value Cross-Validation
        â†“
Hybrid Imputation (Temporal + Spatial)
        â†“
Coverage-Based Trimming
        â†“
Feature Engineering
        â†“
Model Training (XGBoost / LightGBM)
        â†“
Evaluation & Visualization

ğŸ§© Hybrid Imputation Strategy

Missing data is classified per pollutant per station:

Gap Length	Method Used
â‰¤ 6 hours	Linear interpolation
â‰¤ 72 hours	Kalman smoothing
> 72 hours	Spatial IDW
For long gaps, Inverse Distance Weighting (IDW) is applied using neighboring stations, with the power parameter p optimized separately for each pollutant.

ğŸ” IDW Power Optimization

For each pollutant, IDW power p âˆˆ [0.2, 2.0] was selected using cross-validated RMSE over recent historical data.

Pollutant	Best p
PM2.5    	0.20
PM10    	0.20
NOx		0.20
SOâ‚‚	     			0.20
CO		0.29
Oâ‚ƒ      		0.46

ğŸ›  Feature Engineering

Temporal Features

Hour of day

Day of week

Month

Season

Lag & Rolling Features

Lag 1h, 24h, 48h, 72h

Rolling means (24h, 72h)

Spatial Features

Latitude

Longitude

Station ID (categorical)

Final feature table:

~1.75 million rows

42 features

ğŸ¤– Model Training

Two models were trained per pollutant:

Models Used

XGBoost

LightGBM

Validation Strategy

Last 60 days used as test set

All training data strictly precedes test data

Prevents temporal leakage

ğŸ“Š Model Performance
LightGBM Results (RMSE / MAE)
Pollutant	RMSE	MAE
PM2.5		22.07	13.15
PM10		39.84	25.34
NOx		22.66	11.81
SOâ‚‚					3.66	  1.87
CO		0.43	 0.20
Oâ‚ƒ					8.73	  4.72

LightGBM consistently performed slightly better than XGBoost.

ğŸ“ˆ Model Interpretation

Feature importance analysis shows:

Lagged pollutant values dominate predictions

Strong daily and seasonal patterns

Spatial coordinates help distinguish station behavior

Feature importance plots available in results/feature_importance/

ğŸŒ Heatmap Visualization

For each pollutant:

Hourly predictions for 7 days

Interpolated to a spatial grid using IDW

Heatmaps available in results/heatmaps/

ğŸ§ª Time-Series Validation

For selected stations (e.g., Station 5 and Station 33):

Actual vs predicted pollutant concentrations plotted

Confirms temporal consistency and trend capture

Available in results/time_series/

ğŸ—ƒï¸ Repository Structure

Delhi_AQI_index_prediction/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ cleaned/
â”‚   â”œâ”€â”€ interim/
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ 00_load_and_validate.py
â”‚   â”œâ”€â”€ 01_gap_analysis.py
â”‚   â”œâ”€â”€ 01_idw_p_cross_validation.py
â”‚   â”œâ”€â”€ 02_imputation.py
â”‚   â”œâ”€â”€ 02b_validate_imputation.py
â”‚   â”œâ”€â”€ 02c_trim_low_coverage.py
â”‚   â”œâ”€â”€ 03_feature_engineering.py
â”‚   â”œâ”€â”€ 04a_train_xgboost.py
â”‚   â”œâ”€â”€ 04b_train_lightgbm.py
â”‚   â”œâ”€â”€ 04c_feature_importance.py
â”‚   â”œâ”€â”€ 04d_Igb_feature_importance.py
â”‚   â”œâ”€â”€ 04e_export_lightgbm_predictions.py
â”‚   â”œâ”€â”€ 05_error_regime_analysis.py
â”‚   â”œâ”€â”€ 05_forecasting.py
â”‚   â”œâ”€â”€ 05_generate_7day_heatmaps.py
â”‚   â””â”€â”€ 06_accuracy_timeseries.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ xgboost/
â”‚   â””â”€â”€ lightgbm/
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ heatmaps/
â”‚   â””â”€â”€ accuracy_plots/
â”‚
â””â”€â”€ README.md
